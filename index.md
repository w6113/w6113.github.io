---
layout: index
---

<!--<div class="alert alert-success" role="alert">
  <h4 class="alert-heading">Registering for this course</h4>
  <p>If you are interested in taking this course, please fill out 
  <a href="https://forms.gle/Z9RufMdoA1YSfa5HA" style="color:#045321; text-decoration:underline;"><b>THIS SHORT FORM</b></a>.
  Due to the small class size, we will use the answers to balance student backgrounds and expertise.  To ensure commitment, we are not currently accepting audits.  
  </p>
</div>
-->



# Overview


LLMs have opened new possibilities of automated agents that plan and complete tasks on the user’s behalf.  Such agents have the potential to usher in a new industrial revolution by automating organizational processes.   However, agents are currently limited to soft-edge tasks that have large tolerances for error, and are too unreliable for hard-edge tasks, like in healthcare or enterprises, where accuracy and reliability are paramount.  In short, what does it take for agents to be used in enterprises?

This graduate-level course will cut across the technology stack to examine the research questions that need to be answered for agents to be possible in real tasks that matter.    Each session will review 1-3 papers or systems, and discuss research opportunities that arise from the gap between existing research and enterprise requirements.  Topics will span systems (data systems and ML systems), AI (LLMs, agent-based planning), HCI, and theory (reinforcement learning, markets).   

Broad questions include

* What mechanisms are data systems missing to support agents?
* How does human-computer interaction change when the human interacts with agents?
* How can knowledge throughout an organization be used to constrain and improve agentic planning?
* How can systems handle the 10-100x increase in load generated by agents?
* What are the theoretical limits of what agents can do?
* At scale, how will the use of agents affect markets, incentives, and the structure of organizations?



### Class Structure

* There will be assigned readings for each week
* Classes will be a mix of discussion about the papers, speculating about new problems, and external speakers
* Due to the speculative nature of the course, students are expected to co-investigate the problems alongside the instructors.   

# Project ideas

**For 6113 Students Only**: [Google doc with suggestions](https://docs.google.com/document/d/19H-ZQ2ARwy-gUhOoUb9MqyWBNuVzCRTBlsNxAywlChQ/edit).  You are welcome to add your own ideas!



# Tentative Schedule



<span class="date">1/21</span>	<span class="topic">Introduction & a quick history of agents</span>	- Eugene & Kostis


## WHERE WE ARE

<span class="date">1/23</span>	<span class="topic"><a href="https://drive.google.com/file/d/1308CxPBdqhrurz4zeGN5Uw_Xp6BzQaJ1/view?usp=sharing">Tutorial: Agents Overview</a></span> - [Xiao Yu](https://jasonyux.com/), Columbia {% include toggle.html content="I am a second year Ph.D. student in Computer Science at Columbia University advised by Zhou Yu. Before joining the Ph.D. program, I was an undergrad also at Columbia University, majoring in Computer Science and minoring in Applied Physics. Currently I am interested in: 1) Reinforcement Learning + (V)LM Training, and 2) Planning Algorithms + (V)LM Agents. My recent works include developing search algorithms to improve (V)LM's performance on dialogue tasks such as persuasion and agentic tasks such as using a web browser or a virtual machine; and methods to train (V)LMs without extensive human labeling efforts." %}

* Readings
    * [OSWorld](https://arxiv.org/abs/2404.07972)
    * [SWE-agent](https://arxiv.org/abs/2405.15793)
* Questions
    * What are some real life applications that can make use of/benefit from these computer agents? 
    * What are some concerns/limitations?


<span class="date">1/28</span>	<span class="topic"><a href="https://drive.google.com/file/d/1TUZf2GV3zPZA8sLKSSpkp2nd5OT8SSpt/view?usp=sharing">Tutorial: Agent Planning</a></span> - [Xiao Yu](https://jasonyux.com/), Columbia

* Readings
    * [AlphaGo](https://www.nature.com/articles/nature24270)
    * [Reflective-MCTS](https://arxiv.org/abs/2410.02052)
* Questions
    * What other tasks/domains would benefit from these self-learning/planning approaches? 
    * What key limitations or errors should you watch for when using these approaches?



<span class="date">01/30</span> <span class="topic">Background: SWEBench</span> - [John Yang](https://john-b-yang.github.io/), Stanford {% include toggle.html content="John Yang is a PhD student at Stanford University advised by Prof. Diyi Yang and Ludwig Schmidt. He formerly conducted research at Princeton University advised Prof. Karthik Narasimhan. John works on evaluations, data, and systems around Language Model (LM) agents for software engineering" %}

* Readings
  * [SWE-bench: Can Language Models Resolve Real-World GitHub Issues?](https://arxiv.org/abs/2310.06770)
  * [SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering](https://arxiv.org/abs/2405.15793)
* Questions
  * What might the future of evaluations for Language Models and AI Systems look like? Can you think of any real world workflows or pipelines (not necessarily within Software Engineering or Tech) that might be interesting testbeds?
  * How might AI agents be deployed in a real world? How might the responsibilities of a software developer / manager and the technology market itself evolve in response to AI co-pilots?


<span class="date">02/04</span> <span class="topic">Programming Foundation Models</span> [Thomas Joshi](), Columbia {% include toggle.html content="Thomas Joshi is co-author of Stanford DSPy and leads the GenAI Collective, the largest AI community in the US with over 30,000 members across chapters in SF, NYC, Boston, London, Paris, and other cities. DSPy has been used by Nvidia, Microsoft, Meta, NASDAQ, Carlyle, ABN Amro, JetBlue, Cohere, and others. Thomas is passionate about modular approaches to AI system design, enabling engineers to optimize LLM pipelines for performance and cost-efficiency." %}

* Readings
  * [DSPy](https://arxiv.org/abs/2310.03714)
* Questions (rather than answering these, use the questions as a starting point for discussion on slack)
  * Modular frameworks like DSPy enhance flexibility and scalability in agentic systems but may introduce inefficiencies due to communication overhead between modules. How do these trade-offs affect the performance of agents in real-world applications? What strategies could be used to minimize these inefficiencies while retaining the advantages of modularity?
  * DSPy’s modular agents use predefined components tailored to specific tasks, but dynamic environments often demand adaptability. How can agents built with modular frameworks autonomously adapt or reconfigure their modules to address unforeseen challenges? What are the current limitations of modular designs in this context, and how could future advancements improve their adaptability?

<span class="date">02/06</span> <span class="topic">Use Case: Navigating US Disaster Recovery Bureaucracy</span> - [Jeffrey Schlegelmilch](https://ncdp.columbia.edu/about-us/faculty-and-staff/), [National Center for Disaster Preparedness](https://ncdp.columbia.edu/) {% include toggle.html content="Jeff Schlegelmilch is the Director of the National Center for Disaster Preparedness at the Columbia Climate School, as well as the Director of Executive Education and Non-Degree Programs for the Columbia Climate School. He is also an Associate Professor for Professional Practice in Climate. His areas of expertise include public health preparedness, community resilience, and the integration of private and public sector capabilities." %}

* Readings
  * [GAO report on disaster recovery](https://www.gao.gov/products/gao-23-104956) (highlights page is sufficient)
  * [Fema infographic](./files/images/fema.png)
* Questions (use the question as a starting point for discussion on slack)
  * In the absence of wholesale change, how can technology support improving efficiency in the bureaucracy of disaster recovery?

<span class="date">02/11</span> <span class="topic">No Lecture: Project Proposal Submission</span> - Instructors will be around to discuss and provide feedback

<span class="date">02/13</span> <span class="topic">Use Case: Agents in Systems Optimization</span> - [Shreya Shankar](https://www.sh-reya.com/) PhD, UC Berkeley {% include toggle.html content="Shreya Shankar is a PhD student in computer science at UC Berkeley, advised by Dr. Aditya Parameswaran. Her research creates practical tools and frameworks that help people build reliable ML systems, with recent work on declarative interfaces and optimization for unstructured data analysis. Her work appears in top data management and HCI venues like SIGMOD, VLDB, CIDR, CSCW and UIST, and she co-organizes the DEEM workshop at SIGMOD. She is supported by the NDSEG Fellowship. Prior to Berkeley, she worked as an ML engineer after completing her B.S. in computer science at Stanford University. In her free time, she enjoys roasting coffee and is actively trying to reduce her Twitter usage.  " %}

* Readings
  * [DocETL](https://arxiv.org/abs/2410.12189)
  * [Palimpzest](https://arxiv.org/pdf/2405.14696) (cost optimization for LLM-powered data processing)
  * (Optional) [ELEET](https://arxiv.org/abs/2410.22522) (fine-tuning smaller models for optimized query execution)
* Questions (rather than answering these, use the questions as a starting point for discussion on slack)
  1. **Systems**: These systems represent different philosophies about determinism in data processing, both in optimization and execution stages: ELEET aims for deterministic extraction with small models, Palimpzest provides deterministic optimization with non-deterministic execution, and DocETL embraces non-determinism in both optimization (given the agents) and execution. How should we think about reliability and correctness guarantees in these different paradigms?
  2. **Systems**: These systems take different approaches to balancing accuracy vs. cost - DocETL optimizes for accuracy with LLM agents, ELEET uses smaller targeted models, and Palimpzest focuses on cost-effective model orchestration. What engineering principles should guide choosing between these approaches for different use cases? What might a unified framework look like?
  3. **HCI**: In document processing systems like DocETL, LLMs can fail in inconsistent ways - e.g., a single LLM may correctly extract 8 names but miss 2 others from the same document, but extract names from other documents perfectly. Unlike traditional data processing errors that follow patterns (e.g., failing on malformed input), LLM failures seem random and hard to systematize. How should interfaces help users validate results and develop trust, when the underlying operations have this fundamentally unpredictable behavior?
  

<span class="date">02/18</span> <span class="topic">Background: Agent Frameworks</span> - [Phil Calçado](https://philcalcado.com/), [Outropy](https://outropy.ai/) {% include toggle.html content="Phil Calçado is a PhD student at Columbia University advised by [Eugene Wu](https://www.eugenewu.net). His research interests include the design and evaluation of agentic systems, with a focus on the intersection of agents, systems, and society. He is also interested in the social and ethical implications of AI systems, and how to make AI more trustworthy and reliable." %}

* Readings:
  * [Building AI Products](https://philcalcado.com/2024/12/14/building-ai-products-part-i.html)
  * [7 Lessons from building a small-scale AI application](https://www.thelis.org/blog/lessons-from-ai)
  * [Compound AI systems](https://bair.berkeley.edu/blog/2024/02/18/compound-ai-systems/)

* Questions (think about and discuss one or more of these topics on slack))
  * Looking at past transformative technologies like the early internet or mobile applications, we see initial barriers around cost, latency, and complexity—challenges that parallel those of today’s AI agents. What key engineering and scientific breakthroughs enabled these technologies to become practical at scale, and what lessons can we apply to AI agents today?
  * Modern cloud architectures are built around stateless, horizontally scalable services, yet AI agents rely on maintaining context and memory. How can these opposing principles be reconciled when designing scalable AI systems? What emerging architectural patterns might enable both scalability and statefulness?
  * The shift from monolithic models to Compound AI systems—where multiple specialized AI components work together—suggests that system design and integration are becoming as crucial as model capabilities. How does this change the skills required for AI engineering, and what new challenges arise when optimizing multi-agent AI systems?
  
<span class="date">02/20</span> <span class="topic">Background: Foundation Models for Embodied/Physical Agents</span> - [Yunzhu Li](https://yunzhuli.github.io), Columbia {% include toggle.html content="I am an Assistant Professor of Computer Science at Columbia University.  Before joining Columbia, I was an Assistant Professor at UIUC CS. I also spent time as a Postdoc at the Stanford Vision and Learning Lab (SVL), working with Fei-Fei Li and Jiajun Wu. I received my PhD from the Computer Science and Artificial Intelligence Laboratory (CSAIL) at MIT, where I was advised by Antonio Torralba and Russ Tedrake, and I obtained my bachelor's degree from Peking University." %}


<blockquote class="blockquote" p class="ms-5 w-90 text-muted">
<p>
Foundation models, such as GPT-4 Vision, have marked significant achievements in the fields of natural language and vision, demonstrating exceptional abilities to adapt to new tasks and scenarios. However, physical/embodied interaction—such as cooking, cleaning, or caregiving—remains a frontier where foundation models and robotic systems have yet to achieve the desired level of adaptability and generalization.</p>

<p>
In this talk, I will discuss the opportunities for incorporating foundation models into classic robotic pipelines to endow robots/physical agents with capabilities beyond those achievable with traditional robotic tools. The talk will focus on three key improvements in (1) task specification, (2) low-level, and (3) high-level scene modeling. The central idea behind this research is to translate the commonsense knowledge embedded in foundation models into structural priors that can be integrated into robot learning systems. This approach leverages the strengths of different modules (e.g., VLM for task interpretation and constrained optimization for motion planning), achieving the best of both worlds. I will demonstrate how such integration enables robots to interpret instructions provided in free-form natural language, and how foundation models can be augmented with additional memory mechanisms, such as an action-conditioned scene graph, to handle a wide range of real-world manipulation tasks.</p>

<p>
Toward the end of the talk, I will discuss the limitations of the current foundation models, challenges that still lie ahead, and potential avenues to address these challenges</p>
</blockquote>

* Readings
  * https://voxposer.github.io/
  * https://rekep-robot.github.io/
* Questions
  * You’ve already seen numerous practical applications of AI agents powered by foundation models in virtual environments. What do you see as the key opportunities and challenges in extending these capabilities to physical agents, particularly those that interact with the real world through robotic manipulation?
  * Additionally, how do the key considerations and assumptions differ between virtual and physical settings?


<span class="date">02/25</span> <span class="topic">Agent-First Systems</span> - Jerry/Nikos/Peter/Eugene/Kostis, Columbia

<span class="date">02/27</span> <span class="topic">Systems: Lineage and Data-flow policies</span> - [Eugene Wu](https://www.eugenewu.net), Columbia

### WHAT WE WANT

<span class="date">03/04</span> <span class="topic"></span> 

<span class="date">03/06</span> <span class="topic">Models: Neurosymbolic training</span> - [Baishakhi Ray](https://rayb.info), Columbia

<span class="date">03/11</span> <span class="topic">HAI: Hand-offs with humans and context</span> - [Lydia Chilton](https://www.cs.columbia.edu/~chilton/chilton.html), Columbia

<span class="date">03/13</span> <span class="workshop topic">No Class!  Attend the Agents for Work workshop on 3/12 (link in slack)</span>

<span class="date">03/25</span> <span class="topic">Models: Planning</span> - [Shipra Agrawal](https://www.columbia.edu/~sa3305/), Columbia

<span class="date">03/27</span> <span class="topic">Use Case: Financial Products</span> - [Raman Jatkar](https://www.linkedin.com/in/raman-jatkar-7942079), Intellect Design

<span class="date">04/01</span> <span class="topic">HAI: Process Mining and Agents</span> - [Wil van der Aalst](https://en.wikipedia.org/wiki/Wil_van_der_Aalst) (the father of process mining), RWTH Aachen University

<span class="date">04/03</span> <span class="topic">Use Case: Coding (AutoCodeRover)</span> - [Yuntong Zhang](https://yuntongzhang.github.io/), NUS

<!-- <span class="date">04/08</span> <span class="topic">HAI: Schema and Process Induction</span> - Lydia Chilton, Columbia -->
<span class="date">04/08</span> <span class="topic">TBA</span> - Shankar Bhargava, WalmartLabs

<span class="date">04/10</span> <span class="topic">Models: TBA</span> - [Shunyu Yao](https://ysymyth.github.io/), OpenAI

<span class="date">04/15</span> <span class="topic">Agents at Google</span> - [Fatma Ozcan](https://techsysinfra.google/research/srg-staff/fatma-ozcan/), Google Research

<span class="date">04/17</span> <span class="topic">Systems: Security</span> - [Weiliang Zhao](https://www.cs.columbia.edu/~wz2665/weiliang.html), Columbia

<span class="date">04/22</span> <span class="topic">Models: Long context LLM</span> - [Kuntai Du](https://kuntaidu.github.io/aboutme.html), UChicago

<span class="date">04/24</span> <span class="topic">Model Context Protocol</span> - David Sorria Parra and Elie Schoppik, Anthropic

### What You Did

<span class="date">04/29</span> <span class="topic">Presentations</span>

<span class="date">05/01</span> <span class="topic">Presentations</span>



<style>
h3 {
  color: #067832;
  margin-top: 1em;
  margin-bottom: 1em;
}
.date {
color: gray;
background-color: #999;
background-color: #d4f1cc;
color: black;
padding: 2px 6px;
border-radius: 4px;
margin-right: .5em;

}
span.topic {
font-weight: bold;
}
.workshop, .workshop a {
text-transform: uppercase;
}
</style>
